{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![test](https://github.com/OlivierBinette/groupbyrule/actions/workflows/python-package-conda.yml/badge.svg)](https://github.com/OlivierBinette/groupbyrule/actions/workflows/python-package-conda.yml) \n",
    "\n",
    "# :link: GroupByRule: deduplicate data using fuzzy and deterministic matching rules\n",
    "\n",
    "ðŸš§ under construction ðŸš§\n",
    "\n",
    "**GroupByRule** is a Python package for data cleaning and deduplication. It integrates with [pandas](https://pandas.pydata.org/)' [`groupby`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) function to not only group dataframe rows by a given identifier, but also groups rows based on logical rules and partial matching. In other words, it provides tools for deterministic record linkage and entity resolution in structured databases. It can also be used for *blocking*, a form of filtering used to speed-up more complex entity resolution algorithms. See the references below to learn more about these topics.\n",
    "\n",
    "One of the main goal of **GroupByRule** is to be user-friendly. Matching rules and clustering algorithms are composable and the performance of algorithms can be readily evaluated given training data. The package is built on top of [pandas](https://pandas.pydata.org) for data manipulation and on [igraph](https://igraph.org/python/) for graph clustering and related computations.\n",
    "\n",
    "Additionally, **GroupByRule** provides highly efficient C++ implementations of common [string distance functions](https://en.wikipedia.org/wiki/String_metric) through its `comparator` submodule. This can be used independently of record linkage algorithms.\n",
    "\n",
    "## Installation\n",
    "\n",
    "Install from github using the following command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     pip install git+https://github.com/OlivierBinette/groupbyrule.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "### Rule-Based Linkage\n",
    "\n",
    "Consider the `RLdata500` dataset from the [RecordLinkage R package](https://www.google.com/search?channel=fs&client=ubuntu&q=recordlinkage+r+package)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname_c1</th>\n",
       "      <th>fname_c2</th>\n",
       "      <th>lname_c1</th>\n",
       "      <th>lname_c2</th>\n",
       "      <th>by</th>\n",
       "      <th>bm</th>\n",
       "      <th>bd</th>\n",
       "      <th>identity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CARSTEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEIER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1949</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GERD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BAUER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1968</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROBERT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HARTMANN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1930</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STEFAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WOLFF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1957</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RALF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KRUEGER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1966</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fname_c1 fname_c2  lname_c1 lname_c2    by  bm  bd  identity\n",
       "1  CARSTEN      NaN     MEIER      NaN  1949   7  22        34\n",
       "2     GERD      NaN     BAUER      NaN  1968   7  27        51\n",
       "3   ROBERT      NaN  HARTMANN      NaN  1930   4  30       115\n",
       "4   STEFAN      NaN     WOLFF      NaN  1957   9   2       189\n",
       "5     RALF      NaN   KRUEGER      NaN  1966   1  13        72"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from groupbyrule.data import load_RLdata500\n",
    "\n",
    "df = load_RLdata500()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We deduplicate this dataset by linking records which match either on both first name (`fname_c1`) and last name (`lname_c1`), on both first name and birth day (`bd`), or on both last name and birth day. Linkage transitivity is resolved, by default, by considering connected components of the resulting graph. Precision and recall are computed from the ground truth membership vector `identity_RLdata500`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11538461538461539, 0.96)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from groupbyrule import Any, Match, precision_recall\n",
    "\n",
    "# Specify linkage rule\n",
    "rule = Any(Match(\"fname_c1\", \"lname_c1\"),\n",
    "           Match(\"fname_c1\", \"bd\"),\n",
    "           Match(\"lname_c1\", \"bd\"))\n",
    "\n",
    "# Apply the rule to a dataset\n",
    "rule.fit(df)\n",
    "\n",
    "# Evaluate performance by computing precision and recall\n",
    "precision_recall(rule.groups, df.identity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This is not the best way to deduplicate this dataset, but the above showcases the composability of matching rules. The specific rules themselves (exact matching, similarity-based string matching, and different clustering algorithms) can be customized as needed. A more complete overview is available [here]() ðŸš§.\n",
    "\n",
    "A better way to deduplicate this data is to link all pairs of records which agree on all but at most one attribute. This is done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.92)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from groupbyrule import AllButK\n",
    "\n",
    "# Link records agreeing on all but at most k=1 of the specified attributes\n",
    "rule = AllButK(\"fname_c1\", \"lname_c1\", \"bd\", \"bm\", \"by\", k=1)\n",
    "\n",
    "# Apply the rule to a dataset\n",
    "rule.fit(df)\n",
    "\n",
    "# Evaluate performance by computing precision and recall\n",
    "precision_recall(rule.groups, df.identity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postprocessing\n",
    "\n",
    "Following record linkage, records can be processed using pandas's groupby and aggregation functions. Below, we only keep the first non-NA attribute value for each record cluster. This is a simple way to obtain a deduplicated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduplicated = df.groupby(rule.groups).first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Distance Functions\n",
    "\n",
    "**GroupByRule** provides a suite of string and numerical similarity functions as part of its `comparator` submodule. String similarity functions include the Levenshtein distance, the Jaro-Winkler distance, and ðŸš§. These similarity functions can be used on their own as shown below, or for the definition of linkage rules as explained in the following section. This is heavily inspired by Neil Marchant's excellent [Comparator](https://github.com/ngmarchant/comparator) R package, but not quite equivalent in its scope and implementation.\n",
    "\n",
    "String distance functions are implemented through subclasses of the `Comparator` abstract base case. `Comparator` objects are used to instanciate comparison functions while allowing data in memory to be recycled across function calls. The `compare()` method can then be used to compare elements, the `pairwise()` method can be used to compare all pairs of elements between two lists, and the `elementwise()` method can be used to compare corresponding elements.\n",
    "\n",
    "Below are examples of the comparison functions currently provided. These are implemented in C++ for efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from groupbyrule.comparator import Levenshtein\n",
    "\n",
    "cmp = Levenshtein(normalize=True, similarity=False)\n",
    "cmp.compare(\"Olivier\", \"Oilvier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Longest Common Subsequence (LCS) Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from groupbyrule.comparator import LCSDistance\n",
    "\n",
    "cmp = LCSDistance(normalize=True, similarity=False)\n",
    "cmp.compare(\"Olivier\", \"Oilvier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Damerau-Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13333333333333333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from groupbyrule.comparator import DamerauLevenshtein\n",
    "\n",
    "cmp = DamerauLevenshtein(normalize=True, similarity=False)\n",
    "cmp.compare(\"Olivier\", \"Oilvier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jaro Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04761904761904756"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from groupbyrule.comparator import Jaro\n",
    "\n",
    "cmp = Jaro(similarity=False)\n",
    "cmp.compare(\"Olivier\", \"Oilvier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jaro-Winkler Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.042857142857142816"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from groupbyrule.comparator import JaroWinkler\n",
    "\n",
    "cmp = JaroWinkler(similarity=False)\n",
    "cmp.compare(\"Olivier\", \"Oilvier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Similarity-Based Linkage Rules\n",
    "\n",
    "ðŸš§\n",
    "\n",
    "### Supervised Approaches and Learning Rules\n",
    "\n",
    "ðŸš§\n",
    "\n",
    "### Clustering Algorithms\n",
    "\n",
    "ðŸš§\n",
    "\n",
    "### Performance Evaluation\n",
    "\n",
    "ðŸš§\n",
    "\n",
    "### Privacy-Preserving Record Linkage\n",
    "\n",
    "ðŸš§\n",
    "\n",
    "#### Cryptographic Primitives\n",
    "\n",
    "ðŸš§\n",
    "\n",
    "#### Multiparty Computation Protocols\n",
    "\n",
    "ðŸš§\n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "ðŸš§\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b582ae4d77d18d658cc55812e32328158e2f45884933450b1021a6ea5c0413ef"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('groupbyrule': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
